{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6aafaf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a525c0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Kowsalya/Downloads/uber_rides_data.xlsx - sample_train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5760eb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ride_id  fare_amount          pickup_datetime  pickup_longitude  \\\n",
      "0  24238194          7.5  2015-05-07 19:52:06 UTC        -73.999817   \n",
      "1  27835199          7.7  2009-07-17 20:04:56 UTC        -73.994355   \n",
      "2  44984355         12.9  2009-08-24 21:45:00 UTC        -74.005043   \n",
      "3  25894730          5.3  2009-06-26 08:22:21 UTC        -73.976124   \n",
      "4  17610152         16.0  2014-08-28 17:47:00 UTC        -73.925023   \n",
      "\n",
      "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
      "0        40.738354         -73.999512         40.723217                1  \n",
      "1        40.728225         -73.994710         40.750325                1  \n",
      "2        40.740770         -73.962565         40.772647                1  \n",
      "3        40.790844         -73.965316         40.803349                3  \n",
      "4        40.744085         -73.973082         40.761247                5  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e14527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   ride_id            200000 non-null  int64  \n",
      " 1   fare_amount        200000 non-null  float64\n",
      " 2   pickup_datetime    200000 non-null  object \n",
      " 3   pickup_longitude   200000 non-null  float64\n",
      " 4   pickup_latitude    200000 non-null  float64\n",
      " 5   dropoff_longitude  199999 non-null  float64\n",
      " 6   dropoff_latitude   199999 non-null  float64\n",
      " 7   passenger_count    200000 non-null  int64  \n",
      "dtypes: float64(5), int64(2), object(1)\n",
      "memory usage: 12.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17caa433",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9763ef0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataset is: (200000, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the dataset is:\", shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e30d70d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of integer columns (by default): 2\n"
     ]
    }
   ],
   "source": [
    "integer_columns = df.select_dtypes(include=['int64'])\n",
    "num_integer_columns = integer_columns.shape[1]\n",
    "print(\"Number of integer columns (by default):\", num_integer_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "713a3792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'dropoff_longitude' column: 1\n"
     ]
    }
   ],
   "source": [
    "missing_values = df['dropoff_longitude'].isna().sum()\n",
    "print(\"Number of missing values in 'dropoff_longitude' column:\", missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62bdce2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of 'pickup_datetime' feature: object\n"
     ]
    }
   ],
   "source": [
    "pickup_datetime_dtype = df['pickup_datetime'].dtype\n",
    "print(\"Data type of 'pickup_datetime' feature:\", pickup_datetime_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0cfeb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2015-05-07 19:52:06+00:00\n",
       "1        2009-07-17 20:04:56+00:00\n",
       "2        2009-08-24 21:45:00+00:00\n",
       "3        2009-06-26 08:22:21+00:00\n",
       "4        2014-08-28 17:47:00+00:00\n",
       "                    ...           \n",
       "199995   2012-10-28 10:49:00+00:00\n",
       "199996   2014-03-14 01:09:00+00:00\n",
       "199997   2009-06-29 00:42:00+00:00\n",
       "199998   2015-05-20 14:56:25+00:00\n",
       "199999   2010-05-15 04:08:00+00:00\n",
       "Name: pickup_datetime, Length: 200000, dtype: datetime64[ns, UTC]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(df['pickup_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5470d552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24238194</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2015-05-07 19:52:06 UTC</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27835199</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2009-07-17 20:04:56 UTC</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44984355</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2009-08-24 21:45:00 UTC</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25894730</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2009-06-26 08:22:21 UTC</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17610152</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2014-08-28 17:47:00 UTC</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>42598914</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2012-10-28 10:49:00 UTC</td>\n",
       "      <td>-73.987042</td>\n",
       "      <td>40.739367</td>\n",
       "      <td>-73.986525</td>\n",
       "      <td>40.740297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>16382965</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2014-03-14 01:09:00 UTC</td>\n",
       "      <td>-73.984722</td>\n",
       "      <td>40.736837</td>\n",
       "      <td>-74.006672</td>\n",
       "      <td>40.739620</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>27804658</td>\n",
       "      <td>30.9</td>\n",
       "      <td>2009-06-29 00:42:00 UTC</td>\n",
       "      <td>-73.986017</td>\n",
       "      <td>40.756487</td>\n",
       "      <td>-73.858957</td>\n",
       "      <td>40.692588</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>20259894</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2015-05-20 14:56:25 UTC</td>\n",
       "      <td>-73.997124</td>\n",
       "      <td>40.725452</td>\n",
       "      <td>-73.983215</td>\n",
       "      <td>40.695416</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>11951496</td>\n",
       "      <td>14.1</td>\n",
       "      <td>2010-05-15 04:08:00 UTC</td>\n",
       "      <td>-73.984395</td>\n",
       "      <td>40.720077</td>\n",
       "      <td>-73.985508</td>\n",
       "      <td>40.768793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199999 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ride_id  fare_amount          pickup_datetime  pickup_longitude  \\\n",
       "0       24238194          7.5  2015-05-07 19:52:06 UTC        -73.999817   \n",
       "1       27835199          7.7  2009-07-17 20:04:56 UTC        -73.994355   \n",
       "2       44984355         12.9  2009-08-24 21:45:00 UTC        -74.005043   \n",
       "3       25894730          5.3  2009-06-26 08:22:21 UTC        -73.976124   \n",
       "4       17610152         16.0  2014-08-28 17:47:00 UTC        -73.925023   \n",
       "...          ...          ...                      ...               ...   \n",
       "199995  42598914          3.0  2012-10-28 10:49:00 UTC        -73.987042   \n",
       "199996  16382965          7.5  2014-03-14 01:09:00 UTC        -73.984722   \n",
       "199997  27804658         30.9  2009-06-29 00:42:00 UTC        -73.986017   \n",
       "199998  20259894         14.5  2015-05-20 14:56:25 UTC        -73.997124   \n",
       "199999  11951496         14.1  2010-05-15 04:08:00 UTC        -73.984395   \n",
       "\n",
       "        pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0             40.738354         -73.999512         40.723217                1  \n",
       "1             40.728225         -73.994710         40.750325                1  \n",
       "2             40.740770         -73.962565         40.772647                1  \n",
       "3             40.790844         -73.965316         40.803349                3  \n",
       "4             40.744085         -73.973082         40.761247                5  \n",
       "...                 ...                ...               ...              ...  \n",
       "199995        40.739367         -73.986525         40.740297                1  \n",
       "199996        40.736837         -74.006672         40.739620                1  \n",
       "199997        40.756487         -73.858957         40.692588                2  \n",
       "199998        40.725452         -73.983215         40.695416                1  \n",
       "199999        40.720077         -73.985508         40.768793                1  \n",
       "\n",
       "[199999 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94831cf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average fare amount: 11.359955250000626\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = df.dropna(subset=['fare_amount'])\n",
    "average_fare_amount = df_cleaned['fare_amount'].mean()\n",
    "print(\"Average fare amount:\", average_fare_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83bdb13",
   "metadata": {},
   "source": [
    " Function to calculate Haversine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25e2f144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Haversine distance: 2.1209923961833708\n"
     ]
    }
   ],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0\n",
    "    lat1, lon1, lat2, lon2 = np.radians([lat1, lon1, lat2, lon2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "df['haversine_distance'] = df.apply(lambda row: haversine(row['pickup_latitude'], row['pickup_longitude'], row['dropoff_latitude'], row['dropoff_longitude']), axis=1)\n",
    "\n",
    "median_haversine_distance = df['haversine_distance'].median()\n",
    "print(\"Median Haversine distance:\", median_haversine_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebb3bbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Haversine distance: 16409.239135313168\n"
     ]
    }
   ],
   "source": [
    "max_haversine_distance = df['haversine_distance'].max()\n",
    "print(\"Maximum Haversine distance:\", max_haversine_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c16c2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rides with 0.0 Haversine distance: 5632\n"
     ]
    }
   ],
   "source": [
    "zero_haversine_count = (df['haversine_distance'] == 0.0).sum()\n",
    "print(\"Number of rides with 0.0 Haversine distance:\", zero_haversine_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e35ce48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean 'fare_amount' for rides with 0.0 Haversine distance: 11.585317826704578\n"
     ]
    }
   ],
   "source": [
    "mean_fare_amount_zero_haversine = df[df['haversine_distance'] == 0.0]['fare_amount'].mean()\n",
    "print(\"Mean 'fare_amount' for rides with 0.0 Haversine distance:\", mean_fare_amount_zero_haversine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d22ff175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum 'fare_amount' for a ride: 499.0\n"
     ]
    }
   ],
   "source": [
    "max_fare_amount = df['fare_amount'].max()\n",
    "print(\"Maximum 'fare_amount' for a ride:\", max_fare_amount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b68d2f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haversine distance for the costliest ride: 0.0007899213191009994\n"
     ]
    }
   ],
   "source": [
    "costliest_ride = df[df['fare_amount'] == df['fare_amount'].max()]\n",
    "haversine_distance_costliest_ride = haversine(\n",
    "    costliest_ride['pickup_latitude'].values[0],\n",
    "    costliest_ride['pickup_longitude'].values[0],\n",
    "    costliest_ride['dropoff_latitude'].values[0],\n",
    "    costliest_ride['dropoff_longitude'].values[0]\n",
    ")\n",
    "print(\"Haversine distance for the costliest ride:\", haversine_distance_costliest_ride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aceba24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rides recorded in the year 2014: 29968\n"
     ]
    }
   ],
   "source": [
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "df['pickup_year'] = df['pickup_datetime'].dt.year\n",
    "rides_in_2014 = (df['pickup_year'] == 2014).sum()\n",
    "print(\"Number of rides recorded in the year 2014:\", rides_in_2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21f85673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rides recorded in the first quarter of 2014: 7687\n"
     ]
    }
   ],
   "source": [
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "df['pickup_year'] = df['pickup_datetime'].dt.year\n",
    "df['pickup_quarter'] = df['pickup_datetime'].dt.quarter\n",
    "rides_in_q1_2014 = ((df['pickup_year'] == 2014) & (df['pickup_quarter'] == 1)).sum()\n",
    "print(\"Number of rides recorded in the first quarter of 2014:\", rides_in_q1_2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53954421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On which day of the week in September 2010, maximum rides were recorded: Thursday\n"
     ]
    }
   ],
   "source": [
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "df['pickup_year'] = df['pickup_datetime'].dt.year\n",
    "df['pickup_month'] = df['pickup_datetime'].dt.month\n",
    "df['pickup_day_of_week'] = df['pickup_datetime'].dt.day_name()\n",
    "rides_in_september_2010 = (df['pickup_year'] == 2010) & (df['pickup_month'] == 9)\n",
    "rides_by_day_of_week = df[rides_in_september_2010]['pickup_day_of_week'].value_counts()\n",
    "day_with_maximum_rides = rides_by_day_of_week.idxmax()\n",
    "print(\"On which day of the week in September 2010, maximum rides were recorded:\", day_with_maximum_rides)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4284f2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ride_id', 'fare_amount', 'pickup_datetime', 'pickup_longitude',\n",
      "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
      "       'passenger_count', 'haversine_distance', 'pickup_year',\n",
      "       'pickup_quarter', 'pickup_month', 'pickup_day_of_week'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Assuming your DataFrame is named 'df'\n",
    "column_names = df.columns\n",
    "\n",
    "# Print the column names\n",
    "print(column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "12e010ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      "ride_id                         0\n",
      "fare_amount                     0\n",
      "pickup_datetime                 0\n",
      "pickup_longitude                0\n",
      "pickup_latitude                 0\n",
      "dropoff_longitude               0\n",
      "dropoff_latitude                0\n",
      "passenger_count                 0\n",
      "haversine_distance              0\n",
      "pickup_year                     0\n",
      "pickup_quarter                  0\n",
      "pickup_month                    0\n",
      "pickup_day_of_week_Monday       0\n",
      "pickup_day_of_week_Saturday     0\n",
      "pickup_day_of_week_Sunday       0\n",
      "pickup_day_of_week_Thursday     0\n",
      "pickup_day_of_week_Tuesday      0\n",
      "pickup_day_of_week_Wednesday    0\n",
      "dtype: int64\n",
      "Adjusted R-squared values:\n",
      "Linear Regression: 0.015313701699371296\n",
      "Decision Tree Regressor: 0.49338702392492106\n",
      "Random Forest Regressor: 0.6621804867427071\n",
      "K-Nearest Neighbors Regressor: 0.6513636457648535\n",
      "The algorithm with the least adjusted R-squared value is Linear Regression.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Check for missing values in the DataFrame\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Define the input features (X) and the target variable (y)\n",
    "X = df[['passenger_count', 'haversine_distance', 'pickup_year', 'pickup_month', 'pickup_day_of_week_Saturday', 'pickup_day_of_week_Sunday', 'pickup_day_of_week_Thursday', 'pickup_day_of_week_Tuesday', 'pickup_day_of_week_Wednesday']]\n",
    "y = df['fare_amount']\n",
    "\n",
    "# Split the data into training and testing sets (70-30 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree Regressor': DecisionTreeRegressor(),\n",
    "    'Random Forest Regressor': RandomForestRegressor(),\n",
    "    'K-Nearest Neighbors Regressor': KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "adjusted_r2_values = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    n = X_test.shape[0]  \n",
    "    p = X_test.shape[1]  \n",
    "    adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "    adjusted_r2_values[model_name] = adjusted_r2\n",
    "\n",
    "min_adjusted_r2_model = min(adjusted_r2_values, key=adjusted_r2_values.get)\n",
    "\n",
    "print(\"Adjusted R-squared values:\")\n",
    "for model_name, adjusted_r2 in adjusted_r2_values.items():\n",
    "    print(f\"{model_name}: {adjusted_r2}\")\n",
    "\n",
    "print(f\"The algorithm with the least adjusted R-squared value is {min_adjusted_r2_model}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "093ccbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ride_id', 'fare_amount', 'pickup_datetime', 'pickup_longitude',\n",
      "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
      "       'passenger_count', 'haversine_distance', 'pickup_year',\n",
      "       'pickup_quarter', 'pickup_month', 'pickup_day_of_week_Monday',\n",
      "       'pickup_day_of_week_Saturday', 'pickup_day_of_week_Sunday',\n",
      "       'pickup_day_of_week_Thursday', 'pickup_day_of_week_Tuesday',\n",
      "       'pickup_day_of_week_Wednesday'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "48a726c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ride_id', 'fare_amount', 'pickup_datetime', 'pickup_longitude',\n",
      "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
      "       'passenger_count'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print the column names in your DataFrame\n",
    "print(df.columns)\n",
    "\n",
    "# Update the 'features' list to match the column names in your DataFrame\n",
    "features = ['passenger_count', 'haversine_distance', 'pickup_day_of_week']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "07779232",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['passenger_count', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0f4387b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the DataFrame\n",
    "X = df[features].copy()\n",
    "\n",
    "# Handle missing values (if any) in the copied DataFrame\n",
    "X.fillna(0, inplace=True)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "46be1443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression R^2 Score: 0.00034046739678372795\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(X_train, y_train)\n",
    "y_pred = linear_regression.predict(X_test)\n",
    "linear_regression_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Linear Regression R^2 Score:\", linear_regression_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "93606797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor R^2 Score: 0.5556450482225579\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "decision_tree_regressor = DecisionTreeRegressor(random_state=42)\n",
    "decision_tree_regressor.fit(X_train, y_train)\n",
    "decision_tree_r2 = decision_tree_regressor.score(X_test, y_test)\n",
    "\n",
    "print(\"Decision Tree Regressor R^2 Score:\", decision_tree_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6875d849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 200000\n",
      "Number of Columns: 8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Get the number of rows and columns\n",
    "num_rows, num_columns = df.shape\n",
    "\n",
    "print(\"Number of Rows:\", num_rows)\n",
    "print(\"Number of Columns:\", num_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2601b5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor R^2 Score: 0.6468073708472508\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Subsample a portion of your training data (adjust the fraction as needed)\n",
    "sample_fraction = 0.1\n",
    "sample_size = int(len(X_train) * sample_fraction)\n",
    "X_train_subsampled = X_train[:sample_size]\n",
    "y_train_subsampled = y_train[:sample_size]\n",
    "\n",
    "# Initialize and fit the RandomForestRegressor model with fewer trees\n",
    "random_forest_regressor = RandomForestRegressor(n_estimators=5, random_state=42, n_jobs=-1)\n",
    "random_forest_regressor.fit(X_train_subsampled, y_train_subsampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = random_forest_regressor.predict(X_test)\n",
    "\n",
    "# Calculate R^2 score\n",
    "from sklearn.metrics import r2_score\n",
    "random_forest_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Random Forest Regressor R^2 Score:\", random_forest_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0d726b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Regressor R^2 Score: 0.7415787449601723\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the KNN Regressor model with fewer neighbors\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=3)  # Adjust the number of neighbors as needed\n",
    "knn_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the subsampled test set\n",
    "y_pred_knn = knn_regressor.predict(X_test_subsampled)\n",
    "\n",
    "# Calculate R^2 score for KNN Regressor\n",
    "knn_r2 = r2_score(y_test_subsampled, y_pred_knn)\n",
    "\n",
    "print(\"KNN Regressor R^2 Score:\", knn_r2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
